{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa00812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_neo4j import Neo4jChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "CHROMA_PATH_PUBLIC = r\"C:\\Users\\shreyas\\Aerothon\\expirements\\db_root\\public\\Knowledge_vectors\"\n",
    "CHROMA_PATH_SECURE = r\"C:\\Users\\shreyas\\Aerothon\\expirements\\secure_DB\\secure\\Knowledge_vectors\"\n",
    "\n",
    "NEO4J_PUBLIC_URI = \"neo4j://localhost:7687\"\n",
    "NEO4J_SECURE_URI = \"neo4j://localhost:7688\"\n",
    "NEO4J_AUTH = (\"neo4j\", \"password\")\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://127.0.0.1:11434\"\n",
    "MODEL_NAME = \"llama3.1:8b-instruct-q4_K_M\"\n",
    "\n",
    "# --- 2. INITIALIZE ---\n",
    "llm = ChatOllama(model=MODEL_NAME, temperature=0, base_url=OLLAMA_BASE_URL)\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", base_url=OLLAMA_BASE_URL)\n",
    "\n",
    "vectorstore_public = Chroma(persist_directory=CHROMA_PATH_PUBLIC, embedding_function=embeddings)\n",
    "vectorstore_secure = Chroma(persist_directory=CHROMA_PATH_SECURE, embedding_function=embeddings)\n",
    "\n",
    "# --- 3. STRICT RETRIEVAL ---\n",
    "def get_combined_context(query: str):\n",
    "    # Retrieve chunks from both isolated vector stores\n",
    "    public_docs = vectorstore_public.as_retriever(search_kwargs={\"k\": 5}).invoke(query)\n",
    "    secure_docs = vectorstore_secure.as_retriever(search_kwargs={\"k\": 5}).invoke(query)\n",
    "    \n",
    "    # Combined text without invented \"Archive\" labels to stay text-grounded\n",
    "    combined_text = \"\\n\\n\".join([d.page_content for d in (public_docs + secure_docs)])\n",
    "    return combined_text, public_docs + secure_docs\n",
    "\n",
    "# --- 4. CORRECTED CHAT LOGIC ---\n",
    "def experimental_chat(user_input: str, session_id: str, use_secure_history: bool = True):\n",
    "    # Select the isolated Neo4j container for history\n",
    "    history_uri = NEO4J_SECURE_URI if use_secure_history else NEO4J_PUBLIC_URI\n",
    "    \n",
    "    history = Neo4jChatMessageHistory(\n",
    "        url=history_uri, username=NEO4J_AUTH[0], password=NEO4J_AUTH[1], session_id=session_id\n",
    "    )\n",
    "\n",
    "    # 1. Retrieve Context\n",
    "    context_text, all_docs = get_combined_context(user_input)\n",
    "\n",
    "    # 2. Updated Prompt: Enforcing Strict Integrity\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a professional Document Analyst. \n",
    "        \n",
    "        CRITICAL RULES:\n",
    "        1. Answer ONLY using the provided Context. \n",
    "        2. Do NOT introduce external information (phone numbers, emails, or names) not found in the text.\n",
    "        3. If the text provides multiple options, you MUST mention all of them.\n",
    "        4. Use the exact terminology found in the document.\n",
    "        5. If the answer is not in the context, say: 'Information not found in provided materials.'\"\"\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"Context:\\n{context}\\n\\nQuestion: {input}\"),\n",
    "    ])\n",
    "\n",
    "    # 3. Execution\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"chat_history\": history.messages,\n",
    "        \"context\": context_text\n",
    "    })\n",
    "\n",
    "    # 4. Persistence\n",
    "    history.add_user_message(user_input)\n",
    "    history.add_ai_message(response.content)\n",
    "\n",
    "    return response.content, all_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9291c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI RESPONSE:\n",
      "According to the context, Undue Advantage means any information or assistance that a candidate receives from any source during the examination which gives him an unfair advantage over other candidates.\n",
      "\n",
      "Undue advantage arises when a candidate uses any unauthorized material or device during the examination.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    query = \"What is meant by undue advantage, and when does it arise?\"\n",
    "    answer, docs = experimental_chat(query, \"exp_user_02\")\n",
    "    print(f\"AI RESPONSE:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d3343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
